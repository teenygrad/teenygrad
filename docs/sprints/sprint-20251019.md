# Week ending - 19/Oct/2025

## Sprint Goal

- Basic rust function including a call to a triton function compiled to PTX.

### Sprint Tasks

1. Load triton dialect into an appropriate MLIR context. ✅
2. Add support for swapping out the existing rust impl of get_program_id for the matching Triton Op. ✅
3. Configure the triton pass infra to be run against a module.
4. Forward the module that was generated after conversion to LLVM IR to the triton passes.
5. Compile the final module to PTX.

### MVP Tasks

1. Full tensor addition kernel compiled to PTX.
2. Add basic infra for running the kernel.
3. Run and test.

### Tech debt

- egg lang schema is not fit for purpose due to being too generic, this needs to be changed.
- conversions from pytorch schema to our internal schema is not the way Rust does things, this needs to be revisited.
- better error messages for invalid data from pytorch
- centralise rustx compiler dependencies at the workspace level
- investigate the rust lints undefined cfgs in projects such as rustc_llvm
- llvm and triton should be pre-built and available via CI
- improve compilation speed now that the project is much bigger

### Sprint Review

- Was sprint goal achieved?

No, the complete compilation to PTX was not completed. No major blockers, just low velocity this sprint.

- Good
  - All the major compiler related issues now resolved. Compilation to PTX should not be a major problem. The only remaining unknown is the memory layout of the pointers that are passed to triton kernels. As we're currently building a compiler for pytorch that should not be too difficult as triton supports pytorch tensors, but I need to investigate the actual format.

- Bad
  - Low velocity without any major reasons.

- Ugly
  - C++ is horrible, the IDE support in large projects is atrocious.
