# Week ending - 24/Aug/2025

## Sprint Goal

Convert Qwen3 graph to egraph, create a plan on how to implement each of the operations.

### Tasks

1. Capture egraph from fxgraph.
2. For each operation make a detailed plan on how to implement it (e.g. custom triton kernel, existing MLIR dialect, etc).
3. Get new graphics card installed in romulus for development, it's Blackwell compatible to able to use most of the compute capabilities.
4. If time available go through the triton tutorials and puzzles.

### Tech debt

- The existing tech debt is no longer relevant because the IR the system will use will be egraphs. These push a lot of the safety into the analysis phase. Once the basic compiler is done for pytorch, we will need to revisit how the rust neural network API should be structured to work in the new context.

### Sprint Review

- Good
  - Enhaced egraphs flat buffer format to be more strict on what is sent across from python.
  - Checked most of the operations, they require custom triton kernels.
  - New graphics card installed and working with sm_120 compute capability.
  - Completed triton tutorials/puzzles.

- Bad
  - Long holiday weekend disrupted dev work.

- Ugly
  - N/A.

### Fxgraph Ops needed for Qwen3

- embedding : custom kernel
- scaled_dot_product_attention : custom kernel
- silu : custom kernel
- sym_sum
- enter_autocast
- exit_autocast
- lazy_load_decompositions
- getitem
- aten.index
- vmap_increment_nesting
- vmap_decrement_nesting
- add_batch_dim
- remove_batch_dim
- arange
- cat
- iadd
- add
- mul
- matmul
- neg
- rsqrt
- linear
